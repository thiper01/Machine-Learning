{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[{"file_id":"1YdG-XQsw9AEhPdI-WIrRXsSyrMxsF0Cd","timestamp":1669350467620},{"file_id":"https://github.com/Rogerio-mack/IA_2022S2/blob/main/IA_Projeto_N2_template.ipynb","timestamp":1669342125411}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"40b90843"},"source":["<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\"  width=300, align=\"right\">\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","\n","# ***Detecção de Objetos com YOLO e OpenCV***\n","---"]},{"cell_type":"markdown","source":["*Siga esse template para entrega do seu artigo/projeto. O código deste notebook precisa ser 100% executável.*\n","\n","Neste projeto você vai explorar algumas tecnologias que são o estado da arte da IA e do Aprendizado de Máquina. Seu grupo deve escolher uma dentre as seguintes tecnologias ou conceitos para explorar:\n","\n","* **Tools**\n","  * BERT, tradução ou sumarização de texto\n","  * Yolo e OpenCV, para detecção de objetos em Imagens\n","  * Yolo e OpenCV, para detecção de objetos Vídeos\n","\n","* **Conceitos** \n","  * Generative Adversarial Neural Networks\n","  * Transformers (outras aplicações que não NLP, como o BERT)\n","  * Sentiment Analysis (em Português)\n","  * Anomaly Detection \n","\n","Vocês devem produzir um *artigo*, a exemplo de artigos do *Medium* ou outros canais semelhantes, para que seu grupo ou leitores do artigo tenham aqui um ponto de partida para uso da tecnologia/conceito escolhido. \n","\n","<br>\n","\n","<br>\n","\n","**ATENÇÃO**\n","\n","* Podem haver apenas 3 trabalhos para um mesmo tema. \n","* Cadastre o nome completo de 1 aluno do grupo para selecionar o tema aqui [7G](https://docs.google.com/spreadsheets/d/1P4Pw7dXs3d_QGKiT6AmmZo3i4wOvXHhuF8cYWSSidGE/edit?usp=sharing) ou [7N](https://docs.google.com/spreadsheets/d/1QSstslQFsP2ecMlrYbwfQXcP-3stcdYJmb22zvu8ASw/edit?usp=sharing). Respeite a escolha dos Colegas!"],"metadata":{"id":"Ikv-pBzr9bNu"}},{"cell_type":"code","metadata":{"id":"rYx9D4GZA5o9","cellView":"form"},"source":["#@title **Identificação do Grupo**\n","\n","#@markdown Integrantes do Grupo, nome completo em orgem alfabética (*informe \\<TIA\\>,\\<nome\\>*)\n","Aluno1 = '41906861, Fernando Brito de Arruda Bertholino' #@param {type:\"string\"} \n","Aluno2 = '41908961, Gabriel Vitor' #@param {type:\"string\"}\n","Aluno3 = '41905113, Rodrigo Skurczynski' #@param {type:\"string\"}\n","Aluno4 = '41903447, Thiago Perissinotti' #@param {type:\"string\"}\n","Aluno5 = '' #@param {type:\"string\"}\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Resumo (*Abstract*)**\n","\n","\n"],"metadata":{"id":"JlCIc2YooBW7"}},{"cell_type":"markdown","source":["Nosso trabalho se resume em uma IA utilizando YOLO e OpenCV para identificação de objetos em vídeos, por exemplo carros, guarda-chuvas, pessoas, caminhões etc."],"metadata":{"id":"uPAHHPuGj8zv"}},{"cell_type":"markdown","metadata":{"id":"A4-f8AtfKAn2"},"source":["# **Referencial Teórico**\n","\n","Apresente os principais conceitos da tecnologia ou princípio explorado no seu trabalho (o que é? como funciona? Suas aplicações). Não deixe de indicar referências e incluir ilustrações/esquemas quando necessário. Empregue 2-3 páginas. \n","\n","\n","\n"]},{"cell_type":"markdown","source":["# **Conceitos Chave**\n","\n","## 1. *Darknet YOLO* \n","YOLO (You Only Look Once) é um método de fazer a detecção de objetos. É o algoritmo/estratégia por trás de como o código vai detectar objetos na imagem.\n","Estruturas de detecção anteriores examinavam diferentes partes da imagem várias vezes em diferentes escalas e redefiniam a técnica de classificação de imagem para detectar objetos. Essa abordagem é lenta e ineficiente. \n","YOLO adota uma abordagem totalmente diferente. Ele examina a imagem inteira apenas uma vez, passa pela rede uma vez e detecta objetos. Daí o nome. É muito rápido. Essa é a razão pela qual se tornou tão popular.\n","\n","## 2. *OpenCV* \n","OpenCV é uma biblioteca de funções de programação voltada principalmente para visão computacional em tempo real.\n","O módulo DNN (Rede Neural Profunda) fazia inicialmente parte do repositório opencv_contrib. Ele foi movido para o branch master do opencv repo no ano passado, dando aos usuários a capacidade de executar inferência em modelos de aprendizado profundo pré-treinados dentro do próprio OpenCV.\n","(Uma coisa a observar aqui é que o módulo dnn não deve ser usado para treinamento. É apenas para executar inferência em imagens/vídeos.)\n","\n","## 3. *Detecção de Objetos*\n","A detecção de objetos é uma tecnologia de computador relacionada à visão computacional e ao processamento de imagens que lida com a detecção de instâncias de objetos semânticos de uma determinada classe (como humanos, prédios ou carros) em imagens e vídeos digitais. Domínios bem pesquisados de detecção de objetos incluem detecção de rosto e detecção de pedestres. A detecção de objetos tem aplicações em muitas áreas da visão computacional, incluindo recuperação de imagens e vigilância por vídeo."],"metadata":{"id":"69Ed6lD7vmi7"}},{"cell_type":"markdown","source":["# **Exemplo de Aplicação**\n","\n","Um problema que está aplicação pode resolver por exemplo é uma câmera de segurança/detecção de intrusos. Ela pode detectar uma movimentação em lugares calmos, por exemplo em casa, ela pode detectar se é uma pessoa que entrou em casa, se é um pacote que chegou, se é só um carro, se é um gato etc. Dessa forma pode avisar caso tenha uma movimentação de algum objeto, dizer qual foi o objeto, e deixar registrado ou até avisar como alarme.\n","\n","Também é possível lidar com o problema de cuidar de pessoas ou animais que precisam por algum motivo ficar em repouso ou não podem sair de certo local ou demonstrar nenhum movimento. Por exemplo, existem problemas para lidar com pessoas mais idosas que já não estão mais tão cientes do que fazem e ficam tentando fugir de casa. Com essa aplicação é possível uma supervisão constante e remota para verificação desses individuos e sua segurança."],"metadata":{"id":"4wfTEdMMxqFK"}},{"cell_type":"markdown","source":["# **Exemplo de Código**\n","\n"],"metadata":{"id":"FyFHbT8vygVp"}},{"cell_type":"code","source":["# Dependências\n","import cv2\n","import time\n","import numpy as np\n","\n","# Cores\n","COLORS = [(0, 255, 255), (255, 255, 0), (0, 255, 0), (255, 0, 0)]\n","\n","# Carrega as classes\n","class_names = []\n","with open(\"coco.names\", \"r\") as f:\n","    class_names = [cname.strip() for cname in f.readlines()]\n","\n","print(class_names[0])\n","\n","\n","#Captura do video\n","cap = cv2.VideoCapture(\"NY.mp4\")\n","\n","# Carrega os pesos da REDE NEURAL\n","# net = cv2.dnn.readNet(\"yolov4.weights\", \"yolov4.cfg\")\n","net = cv2.dnn.readNet(\"yolov4-tiny.weights\", \"yolov4-tiny.cfg\")\n","\n","# Seta os parâmetros da NN\n","model = cv2.dnn_DetectionModel(net)\n","model.setInputParams(size=(416, 416), scale=1/255)\n","\n","# Lendo Frame a Frame do Video\n","while True:\n","\n","    # Captura Frame\n","    _, frame = cap.read()\n","\n","    # Começo da contagem dos MS\n","    start = time.time()\n","\n","\n","    # Detecção\n","    classes, scores, boxes = model.detect(frame, 0.1, 0.2)\n","\n","    # Fim da contagem dos MS\n","    end = time.time()\n","\n","    # Percorrer todas as detecções\n","    for (classid, score, box) in zip(classes, scores, boxes):\n","\n","        # Gerando uma cor para a classe\n","        color = COLORS[int(classid) % len(COLORS)]\n","\n","        # Pegando o nome da classe pelo ID e o seu score de acuracia\n","        # label = f\"{class_names[classid]} : {score}\"\n","        label = f\"{class_names[classid]}\"\n","\n","        # Desenha a caixa de detecção\n","        cv2.rectangle(frame, box, color, 2)\n","\n","        # Escrevendo o nome da classe em cima da caixa\n","        cv2.putText(frame, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n","\n","    # Calculando o tempo que levou para fazer a detecção\n","    fps_label = f\"FPS: {round((1.0/(end - start)), 2)}\"\n","\n","    # Escrevendo o FPS na imagem\n","    cv2.putText(frame, fps_label, (0, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 5)\n","    cv2.putText(frame, fps_label, (0, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)\n","\n","    # Mostrando a Imagem\n","    cv2.imshow(\"detections\", frame)\n","\n","    # Espera da Resposta\n","    if cv2.waitKey(1) == 27:\n","        break\n","\n","# Liberação da camera e destroi todas as janelas\n","cap.release()\n","cv2.destroyAllWindows()"],"metadata":{"id":"47WSkdIDxpjM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Uma ideia de Projeto de Aplicação**\n","\n","Essa tecnologia pode ser utilizada por exemplo para medição de velocidade de diferentes tipos de veículos em movimento. A medida que a IA vai detectando o objeto, ela já diferencia de carro, caminhão, ônibus etc. Dessa forma já temos a diferenciação do veículo. Então, nós podemos realizar um cálculo para verificar a velocidade do veículo baseado em seu movimento no vídeo, conseguindo aplicar multas automáticas por exemplo para cada tipo específico de veículo.\n"],"metadata":{"id":"vuisqDoJ0oTB"}},{"cell_type":"markdown","source":["# **Referências**\n","\n","https://www.youtube.com/watch?v=Sx_HioMUtiY&t=26s&ab_channel=Jo%C3%A3oReis"],"metadata":{"id":"7LtXrRFr4hg3"}},{"cell_type":"markdown","source":["# **Vídeo, GitHub e Publicação (opcional)** \n","\n","Produza um vídeo explicativo apresentando o seu trabalho. Salve em uma GitHub público seu notebook e o código completo (sem o texto intercalado) do seu projeto. Se bem avaliado, podemos publicar seu texto no Medium. "],"metadata":{"id":"ZGpU-v6CnTaG"}},{"cell_type":"markdown","metadata":{"id":"9kwoGZeSLRsX"},"source":["# **Conclusão** \n","\n","Apresente a conclusão do seu estudo. Indique limitações da tecnologia/conceitos, novos avanços e compare com tecnologias/conceitos concorrentes.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8crUBC3IQ3U_"},"source":["---"]},{"cell_type":"code","metadata":{"id":"BluFtfHuCGzm","cellView":"form"},"source":["#@title **Avaliação**\n","Referencial_Teorico = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n","\n","Conceitos_Chave = 9 #@param {type:\"slider\", min:0, max:10, step:1}\n","\n","Exemplo_Aplicacao = 6 #@param {type:\"slider\", min:0, max:10, step:1}\n","\n","Ideia_Projeto = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n","\n","Conclusao = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"2Gqw7hUZHyle","cellView":"form","outputId":"632a2c94-4a20-4aca-a86a-82cfdcb35db6"},"source":["#@title **Nota Final**\n","nota = Referencial_Teorico + Conceitos_Chave + 2*Exemplo_Aplicacao + 2*Ideia_Projeto + Conclusao\n","\n","nota = nota / 7\n","\n","print(f'Nota final do trabalho {nota :.1f}')\n","\n","import numpy as np\n","import pandas as pd\n","\n","alunos = pd.DataFrame()\n","\n","lista_tia = []\n","lista_nome = []\n","\n","for i in range(1,6):\n","  exec(\"if Aluno\" + str(i) + \" !='None':  lista = Aluno\" + str(i) + \".split(','); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())\")\n","\n","alunos['tia'] = lista_tia\n","alunos['nome'] = lista_nome\n","alunos['nota'] = np.round(nota,1)\n","print()\n","display(alunos)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Nota final do trabalho 7.4\n","\n"]},{"output_type":"display_data","data":{"text/plain":["       tia              nome  nota\n","0  1115665    ADRIANA FUJITA   7.4\n","1  1115677   DANIEL HENRIQUE   7.4"],"text/html":["\n","  <div id=\"df-4a7ed510-daec-4c44-af42-275bebfa0a34\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tia</th>\n","      <th>nome</th>\n","      <th>nota</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1115665</td>\n","      <td>ADRIANA FUJITA</td>\n","      <td>7.4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1115677</td>\n","      <td>DANIEL HENRIQUE</td>\n","      <td>7.4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a7ed510-daec-4c44-af42-275bebfa0a34')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4a7ed510-daec-4c44-af42-275bebfa0a34 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4a7ed510-daec-4c44-af42-275bebfa0a34');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]}]}